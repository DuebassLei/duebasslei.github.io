---
title: Kafkaå®ç”¨æ“ä½œç¬”è®°
description: KafkaåŸºç¡€æ ¸å¿ƒçŸ¥è¯†åŠå¸¸ç”¨æ“ä½œæ•´ç†
tag:
  - Kafka
  - æ¶ˆæ¯é˜Ÿåˆ—
  - æµå¤„ç†
sidebar: true
outline: [2,3,4]
lastUpdated: true
---

## ğŸ“– ç›®å½•

- [Kafka åŸºç¡€æ¦‚å¿µ](#kafka-åŸºç¡€æ¦‚å¿µ)
- [æ ¸å¿ƒç»„ä»¶](#æ ¸å¿ƒç»„ä»¶)
- [Producerï¼ˆç”Ÿäº§è€…ï¼‰](#producerç”Ÿäº§è€…)
- [Consumerï¼ˆæ¶ˆè´¹è€…ï¼‰](#consumeræ¶ˆè´¹è€…)
- [Topic å’Œ Partition](#topic-å’Œ-partition)
- [Consumer Group](#consumer-group)
- [å¸¸ç”¨å‘½ä»¤](#å¸¸ç”¨å‘½ä»¤)
- [é…ç½®ç®¡ç†](#é…ç½®ç®¡ç†)
- [Kafka Streams](#kafka-streams)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## Kafka åŸºç¡€æ¦‚å¿µ

### ä»€ä¹ˆæ˜¯ Kafkaï¼Ÿ

Apache Kafka æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼æµå¤„ç†å¹³å°ï¼Œç”¨äºæ„å»ºå®æ—¶æ•°æ®ç®¡é“å’Œæµå¼åº”ç”¨ç¨‹åºã€‚å®ƒå…·æœ‰é«˜ååé‡ã€å¯æ‰©å±•æ€§å’Œå®¹é”™æ€§ã€‚

### æ ¸å¿ƒç‰¹æ€§

- **é«˜ååé‡**ï¼šæ”¯æŒç™¾ä¸‡çº§æ¶ˆæ¯å¤„ç†
- **å¯æ‰©å±•æ€§**ï¼šæ°´å¹³æ‰©å±•ï¼Œæ·»åŠ èŠ‚ç‚¹å³å¯å¢åŠ å®¹é‡
- **æŒä¹…åŒ–**ï¼šæ¶ˆæ¯æŒä¹…åŒ–åˆ°ç£ç›˜
- **å®¹é”™æ€§**ï¼šé€šè¿‡å‰¯æœ¬æœºåˆ¶ä¿è¯é«˜å¯ç”¨
- **å®æ—¶æ€§**ï¼šä½å»¶è¿Ÿæ¶ˆæ¯ä¼ é€’
- **åˆ†å¸ƒå¼**ï¼šæ”¯æŒå¤šèŠ‚ç‚¹é›†ç¾¤

### åº”ç”¨åœºæ™¯

- **æ¶ˆæ¯é˜Ÿåˆ—**ï¼šè§£è€¦ç³»ç»Ÿï¼Œå¼‚æ­¥å¤„ç†
- **æ—¥å¿—æ”¶é›†**ï¼šé›†ä¸­å¼æ—¥å¿—ç®¡ç†
- **æµå¤„ç†**ï¼šå®æ—¶æ•°æ®å¤„ç†å’Œåˆ†æ
- **äº‹ä»¶æº¯æº**ï¼šè®°å½•æ‰€æœ‰äº‹ä»¶å˜æ›´
- **æŒ‡æ ‡æ”¶é›†**ï¼šç›‘æ§å’ŒæŒ‡æ ‡æ•°æ®æ”¶é›†

---

## æ ¸å¿ƒç»„ä»¶

### Brokerï¼ˆä»£ç†ï¼‰

Kafka é›†ç¾¤ä¸­çš„æœåŠ¡å™¨èŠ‚ç‚¹ï¼Œè´Ÿè´£å­˜å‚¨å’Œè½¬å‘æ¶ˆæ¯ã€‚

```bash
# å¯åŠ¨ Kafka Broker
bin/kafka-server-start.sh config/server.properties
```

### Topicï¼ˆä¸»é¢˜ï¼‰

æ¶ˆæ¯çš„é€»è¾‘åˆ†ç±»ï¼Œç±»ä¼¼äºæ•°æ®åº“ä¸­çš„è¡¨ã€‚

### Partitionï¼ˆåˆ†åŒºï¼‰

Topic çš„ç‰©ç†åˆ†å‰²ï¼Œæ¯ä¸ª Partition æ˜¯ä¸€ä¸ªæœ‰åºçš„æ¶ˆæ¯é˜Ÿåˆ—ã€‚

### Producerï¼ˆç”Ÿäº§è€…ï¼‰

å‘ Kafka Topic å‘é€æ¶ˆæ¯çš„å®¢æˆ·ç«¯ã€‚

### Consumerï¼ˆæ¶ˆè´¹è€…ï¼‰

ä» Kafka Topic è¯»å–æ¶ˆæ¯çš„å®¢æˆ·ç«¯ã€‚

### Consumer Groupï¼ˆæ¶ˆè´¹è€…ç»„ï¼‰

ä¸€ç»„å…±åŒæ¶ˆè´¹ä¸€ä¸ª Topic çš„ Consumer é›†åˆã€‚

### Offsetï¼ˆåç§»é‡ï¼‰

æ¶ˆæ¯åœ¨ Partition ä¸­çš„ä½ç½®æ ‡è¯†ã€‚

---

## Producerï¼ˆç”Ÿäº§è€…ï¼‰

### Java Producer ç¤ºä¾‹

```java
import org.apache.kafka.clients.producer.*;
import java.util.Properties;

// Producer é…ç½®
Properties props = new Properties();
props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, 
          "org.apache.kafka.common.serialization.StringSerializer");
props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, 
          "org.apache.kafka.common.serialization.StringSerializer");
props.put(ProducerConfig.ACKS_CONFIG, "all");  // ç­‰å¾…æ‰€æœ‰å‰¯æœ¬ç¡®è®¤
props.put(ProducerConfig.RETRIES_CONFIG, 3);
props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);
props.put(ProducerConfig.LINGER_MS_CONFIG, 1);
props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);

// åˆ›å»º Producer
KafkaProducer<String, String> producer = new KafkaProducer<>(props);

// å‘é€æ¶ˆæ¯
ProducerRecord<String, String> record = 
    new ProducerRecord<>("my-topic", "key", "value");

producer.send(record, new Callback() {
    @Override
    public void onCompletion(RecordMetadata metadata, Exception exception) {
        if (exception == null) {
            System.out.printf("Message sent: topic=%s, partition=%d, offset=%d%n",
                metadata.topic(), metadata.partition(), metadata.offset());
        } else {
            exception.printStackTrace();
        }
    }
});

// å…³é—­ Producer
producer.close();
```

### äº‹åŠ¡æ€§ Producer

```java
Properties props = new Properties();
props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);
props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, "prod-1");
props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, 
          "org.apache.kafka.common.serialization.StringSerializer");
props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, 
          "org.apache.kafka.common.serialization.StringSerializer");

KafkaProducer<String, String> producer = new KafkaProducer<>(props);

// åˆå§‹åŒ–äº‹åŠ¡
producer.initTransactions();

try {
    // å¼€å§‹äº‹åŠ¡
    producer.beginTransaction();
    
    // å‘é€å¤šæ¡æ¶ˆæ¯ï¼ˆåŸå­æ€§ï¼‰
    producer.send(new ProducerRecord<>("topic1", "key1", "value1"));
    producer.send(new ProducerRecord<>("topic2", "key2", "value2"));
    
    // æäº¤äº‹åŠ¡
    producer.commitTransaction();
} catch (Exception e) {
    // å›æ»šäº‹åŠ¡
    producer.abortTransaction();
}

producer.close();
```

### Producer é…ç½®å‚æ•°

```java
// å…³é”®é…ç½®
props.put(ProducerConfig.ACKS_CONFIG, "all");  // 0, 1, all
props.put(ProducerConfig.RETRIES_CONFIG, 3);
props.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, 5);
props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "snappy");  // gzip, snappy, lz4
props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);
props.put(ProducerConfig.LINGER_MS_CONFIG, 10);
```

---

## Consumerï¼ˆæ¶ˆè´¹è€…ï¼‰

### Java Consumer ç¤ºä¾‹

```java
import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.TopicPartition;
import java.time.Duration;
import java.util.*;

// Consumer é…ç½®
Properties props = new Properties();
props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
props.put(ConsumerConfig.GROUP_ID_CONFIG, "my-consumer-group");
props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, 
          "org.apache.kafka.common.serialization.StringDeserializer");
props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, 
          "org.apache.kafka.common.serialization.StringDeserializer");
props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");  // earliest, latest, none
props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);  // æ‰‹åŠ¨æäº¤ offset
props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);

// åˆ›å»º Consumer
KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);

// è®¢é˜… Topic
consumer.subscribe(Collections.singletonList("my-topic"));

try {
    while (true) {
        // æ‹‰å–æ¶ˆæ¯
        ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
        
        for (ConsumerRecord<String, String> record : records) {
            System.out.printf("offset=%d, key=%s, value=%s%n",
                record.offset(), record.key(), record.value());
            
            // å¤„ç†æ¶ˆæ¯
            processRecord(record);
        }
        
        // æ‰‹åŠ¨æäº¤ offset
        consumer.commitSync();
    }
} finally {
    consumer.close();
}
```

### æ‰‹åŠ¨åˆ†é… Partition

```java
KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);

// æ‰‹åŠ¨åˆ†é… Partitionï¼ˆä¸ä½¿ç”¨ Consumer Groupï¼‰
TopicPartition partition0 = new TopicPartition("my-topic", 0);
TopicPartition partition1 = new TopicPartition("my-topic", 1);
consumer.assign(Arrays.asList(partition0, partition1));

// å®šä½åˆ°ç‰¹å®š offset
consumer.seek(partition0, 100L);

// å®šä½åˆ°å¼€å§‹
consumer.seekToBeginning(Collections.singletonList(partition0));

// å®šä½åˆ°ç»“æŸ
consumer.seekToEnd(Collections.singletonList(partition1));

// æŒ‰æ—¶é—´æˆ³å®šä½
Map<TopicPartition, Long> timestamps = new HashMap<>();
timestamps.put(partition0, System.currentTimeMillis() - 3600000);  // 1å°æ—¶å‰
Map<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(timestamps);
offsets.forEach((tp, offsetAndTimestamp) -> {
    if (offsetAndTimestamp != null) {
        consumer.seek(tp, offsetAndTimestamp.offset());
    }
});
```

### Consumer é…ç½®å‚æ•°

```java
props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);
props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 5000);
props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 30000);
props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);
props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 300000);
props.put(ConsumerConfig.FETCH_MIN_BYTES_CONFIG, 1);
props.put(ConsumerConfig.FETCH_MAX_WAIT_MS_CONFIG, 500);
```

---

## Topic å’Œ Partition

### åˆ›å»º Topic

```bash
# åˆ›å»º Topic
bin/kafka-topics.sh --bootstrap-server localhost:9092 \
  --create \
  --topic my-topic \
  --partitions 3 \
  --replication-factor 2

# æŸ¥çœ‹ Topic åˆ—è¡¨
bin/kafka-topics.sh --bootstrap-server localhost:9092 --list

# æŸ¥çœ‹ Topic è¯¦æƒ…
bin/kafka-topics.sh --bootstrap-server localhost:9092 \
  --describe \
  --topic my-topic

# ä¿®æ”¹ Partition æ•°é‡
bin/kafka-topics.sh --bootstrap-server localhost:9092 \
  --alter \
  --topic my-topic \
  --partitions 5

# åˆ é™¤ Topic
bin/kafka-topics.sh --bootstrap-server localhost:9092 \
  --delete \
  --topic my-topic
```

### Topic é…ç½®

```bash
# åˆ›å»ºå¸¦é…ç½®çš„ Topic
bin/kafka-topics.sh --bootstrap-server localhost:9092 \
  --create \
  --topic my-topic \
  --partitions 3 \
  --replication-factor 2 \
  --config retention.ms=86400000 \
  --config cleanup.policy=delete

# ä¿®æ”¹ Topic é…ç½®
bin/kafka-configs.sh --bootstrap-server localhost:9092 \
  --alter \
  --entity-type topics \
  --entity-name my-topic \
  --add-config retention.ms=172800000

# æŸ¥çœ‹ Topic é…ç½®
bin/kafka-configs.sh --bootstrap-server localhost:9092 \
  --describe \
  --entity-type topics \
  --entity-name my-topic
```

### ä½¿ç”¨ Admin API ç®¡ç† Topic

```java
import org.apache.kafka.clients.admin.*;
import java.util.*;

Properties props = new Properties();
props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");

try (Admin admin = Admin.create(props)) {
    // åˆ›å»º Topic
    NewTopic newTopic = new NewTopic("my-topic", 3, (short) 2);
    CreateTopicsResult result = admin.createTopics(
        Collections.singleton(newTopic));
    result.all().get();
    
    // åˆ—å‡ºæ‰€æœ‰ Topic
    ListTopicsResult listTopics = admin.listTopics();
    Set<String> topics = listTopics.names().get();
    
    // æè¿° Topic
    DescribeTopicsResult describeTopics = admin.describeTopics(
        Collections.singleton("my-topic"));
    TopicDescription description = describeTopics.allTopicNames().get()
        .get("my-topic");
    
    // åˆ é™¤ Topic
    DeleteTopicsResult deleteResult = admin.deleteTopics(
        Collections.singleton("my-topic"));
    deleteResult.all().get();
}
```

---

## Consumer Group

### Consumer Group æ¦‚å¿µ

- **è´Ÿè½½å‡è¡¡**ï¼šå¤šä¸ª Consumer å…±åŒæ¶ˆè´¹ä¸€ä¸ª Topic
- **å®¹é”™æ€§**ï¼šConsumer æ•…éšœæ—¶è‡ªåŠ¨é‡æ–°åˆ†é… Partition
- **Offset ç®¡ç†**ï¼šGroup çº§åˆ«çš„ Offset æäº¤

### ç®¡ç† Consumer Group

```bash
# åˆ—å‡ºæ‰€æœ‰ Consumer Group
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list

# æŸ¥çœ‹ Consumer Group è¯¦æƒ…
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --describe \
  --group my-consumer-group

# æŸ¥çœ‹ Group çš„ Offset ä¿¡æ¯
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --describe \
  --group my-consumer-group \
  --state

# é‡ç½® Consumer Group Offset
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --group my-consumer-group \
  --topic my-topic \
  --reset-offsets \
  --to-earliest \
  --execute

# åˆ é™¤ Consumer Group
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --delete \
  --group my-consumer-group
```

### ä½¿ç”¨ Admin API ç®¡ç† Consumer Group

```java
try (Admin admin = Admin.create(props)) {
    // åˆ—å‡º Consumer Group
    ListConsumerGroupsResult listGroups = admin.listConsumerGroups();
    Collection<ConsumerGroupListing> groups = listGroups.all().get();
    
    // æè¿° Consumer Group
    String groupId = "my-consumer-group";
    DescribeConsumerGroupsResult describeResult = 
        admin.describeConsumerGroups(Collections.singleton(groupId));
    ConsumerGroupDescription groupDescription = 
        describeResult.all().get().get(groupId);
    
    // æŸ¥çœ‹ Group Offset
    ListConsumerGroupOffsetsResult offsetsResult = 
        admin.listConsumerGroupOffsets(groupId);
    Map<TopicPartition, OffsetAndMetadata> offsets = 
        offsetsResult.partitionsToOffsetAndMetadata().get();
    
    // é‡ç½® Offset
    Map<TopicPartition, OffsetAndMetadata> offsetsToAlter = new HashMap<>();
    offsetsToAlter.put(new TopicPartition("my-topic", 0), 
                      new OffsetAndMetadata(100L));
    admin.alterConsumerGroupOffsets(groupId, offsetsToAlter).all().get();
    
    // åˆ é™¤ Consumer Group
    admin.deleteConsumerGroups(Collections.singleton(groupId)).all().get();
}
```

---

## å¸¸ç”¨å‘½ä»¤

### æ§åˆ¶å° Producer

```bash
# å‘é€æ¶ˆæ¯
bin/kafka-console-producer.sh --bootstrap-server localhost:9092 \
  --topic my-topic

# æŒ‡å®š Key
bin/kafka-console-producer.sh --bootstrap-server localhost:9092 \
  --topic my-topic \
  --property "parse.key=true" \
  --property "key.separator=:"
```

### æ§åˆ¶å° Consumer

```bash
# æ¶ˆè´¹æ¶ˆæ¯
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
  --topic my-topic

# ä»å¼€å§‹æ¶ˆè´¹
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
  --topic my-topic \
  --from-beginning

# æŒ‡å®š Consumer Group
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
  --topic my-topic \
  --group my-group

# æ˜¾ç¤º Key å’Œ Value
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
  --topic my-topic \
  --property print.key=true \
  --property print.value=true \
  --property key.separator=":"
```

### æŸ¥çœ‹æ¶ˆæ¯

```bash
# æŸ¥çœ‹ Topic ä¸­çš„æ¶ˆæ¯ï¼ˆä¸æ¶ˆè´¹ï¼‰
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
  --topic my-topic \
  --from-beginning \
  --max-messages 10
```

---

## é…ç½®ç®¡ç†

### Broker é…ç½®

```properties
# server.properties

# Broker ID
broker.id=0

# ç›‘å¬åœ°å€
listeners=PLAINTEXT://localhost:9092

# æ—¥å¿—ç›®å½•
log.dirs=/tmp/kafka-logs

# Topic é»˜è®¤åˆ†åŒºæ•°
num.partitions=3

# é»˜è®¤å‰¯æœ¬æ•°
default.replication.factor=2

# æ—¥å¿—ä¿ç•™æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
log.retention.hours=168

# æ—¥å¿—ä¿ç•™å¤§å°
log.retention.bytes=1073741824

# æ—¥å¿—æ®µå¤§å°
log.segment.bytes=1073741824

# Zookeeper è¿æ¥ï¼ˆå¦‚æœä½¿ç”¨ï¼‰
zookeeper.connect=localhost:2181
```

### åŠ¨æ€ä¿®æ”¹é…ç½®

```bash
# ä¿®æ”¹ Broker é…ç½®
bin/kafka-configs.sh --bootstrap-server localhost:9092 \
  --alter \
  --entity-type brokers \
  --entity-name 1 \
  --add-config num.io.threads=5

# æŸ¥çœ‹ Broker é…ç½®
bin/kafka-configs.sh --bootstrap-server localhost:9092 \
  --describe \
  --entity-type brokers \
  --entity-name 1
```

---

## Kafka Streams

### åŸºæœ¬æ¦‚å¿µ

Kafka Streams æ˜¯ç”¨äºæ„å»ºæµå¤„ç†åº”ç”¨ç¨‹åºçš„å®¢æˆ·ç«¯åº“ã€‚

### WordCount ç¤ºä¾‹

```java
import org.apache.kafka.streams.*;
import org.apache.kafka.streams.kstream.*;
import java.util.Arrays;
import java.util.Properties;

Properties props = new Properties();
props.put(StreamsConfig.APPLICATION_ID_CONFIG, "wordcount-app");
props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, 
          Serdes.String().getClass());
props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, 
          Serdes.String().getClass());

StreamsBuilder builder = new StreamsBuilder();

// ä»è¾“å…¥ Topic è¯»å–
KStream<String, String> textLines = builder.stream("streams-plaintext-input");

// å¤„ç†ï¼šåˆ†å‰²å•è¯å¹¶è®¡æ•°
KTable<String, Long> wordCounts = textLines
    .flatMapValues(value -> Arrays.asList(value.toLowerCase().split("\\W+")))
    .groupBy((key, word) -> word)
    .count();

// å†™å…¥è¾“å‡º Topic
wordCounts.toStream().to("streams-wordcount-output", 
    Produced.with(Serdes.String(), Serdes.Long()));

KafkaStreams streams = new KafkaStreams(builder.build(), props);
streams.start();

// æ·»åŠ å…³é—­é’©å­
Runtime.getRuntime().addShutdownHook(new Thread(streams::close));
```

### Streams é…ç½®

```java
props.put(StreamsConfig.APPLICATION_ID_CONFIG, "my-streams-app");
props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, 
          Serdes.String().getClass());
props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, 
          Serdes.String().getClass());
props.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 30000);
props.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 10485760);
props.put(StreamsConfig.NUM_STANDBY_REPLICAS_CONFIG, 1);
```

---

## æœ€ä½³å®è·µ

### Producer æœ€ä½³å®è·µ

- **æ‰¹é‡å‘é€**ï¼šåˆç†è®¾ç½® `batch.size` å’Œ `linger.ms`
- **å‹ç¼©**ï¼šä½¿ç”¨å‹ç¼©å‡å°‘ç½‘ç»œä¼ è¾“ï¼ˆsnappyã€gzipã€lz4ï¼‰
- **é‡è¯•æœºåˆ¶**ï¼šè®¾ç½®åˆç†çš„é‡è¯•æ¬¡æ•°å’Œé‡è¯•é—´éš”
- **å¹‚ç­‰æ€§**ï¼šå¯ç”¨ `enable.idempotence` ä¿è¯æ¶ˆæ¯ä¸é‡å¤
- **äº‹åŠ¡**ï¼šéœ€è¦è·¨ Topic åŸå­æ€§æ—¶ä½¿ç”¨äº‹åŠ¡

```java
// æ¨èé…ç½®
props.put(ProducerConfig.ACKS_CONFIG, "all");
props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);
props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "snappy");
props.put(ProducerConfig.BATCH_SIZE_CONFIG, 32768);
props.put(ProducerConfig.LINGER_MS_CONFIG, 10);
```

### Consumer æœ€ä½³å®è·µ

- **æ‰¹é‡å¤„ç†**ï¼šåˆç†è®¾ç½® `max.poll.records`
- **æ‰‹åŠ¨æäº¤**ï¼šå…³é”®ä¸šåŠ¡ä½¿ç”¨æ‰‹åŠ¨æäº¤ Offset
- **é”™è¯¯å¤„ç†**ï¼šå®ç°é‡è¯•å’Œæ­»ä¿¡é˜Ÿåˆ—æœºåˆ¶
- **Rebalance å¤„ç†**ï¼šå®ç° `ConsumerRebalanceListener`
- **Offset ç®¡ç†**ï¼šå®šæœŸæ£€æŸ¥ Lagï¼ŒåŠæ—¶å¤„ç†ç§¯å‹

```java
// æ¨èé…ç½®
props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);
props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 30000);
props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 300000);
```

### Topic è®¾è®¡æœ€ä½³å®è·µ

- **åˆ†åŒºæ•°**ï¼šæ ¹æ®ååé‡éœ€æ±‚è®¾ç½®ï¼Œé€šå¸¸ä¸º Consumer æ•°é‡çš„å€æ•°
- **å‰¯æœ¬æ•°**ï¼šç”Ÿäº§ç¯å¢ƒè‡³å°‘ 3 ä¸ªå‰¯æœ¬
- **ä¿ç•™ç­–ç•¥**ï¼šæ ¹æ®ä¸šåŠ¡éœ€æ±‚è®¾ç½® `retention.ms` æˆ– `retention.bytes`
- **å‹ç¼©ç­–ç•¥**ï¼šæ—¥å¿—ç±»æ•°æ®ä½¿ç”¨ `delete`ï¼Œéœ€è¦ä¿ç•™å†å²ä½¿ç”¨ `compact`

```bash
# æ¨èé…ç½®
bin/kafka-topics.sh --bootstrap-server localhost:9092 \
  --create \
  --topic my-topic \
  --partitions 6 \
  --replication-factor 3 \
  --config retention.ms=604800000 \
  --config cleanup.policy=delete
```

### æ€§èƒ½ä¼˜åŒ–

- **æ‰¹é‡æ“ä½œ**ï¼šProducer å’Œ Consumer éƒ½ä½¿ç”¨æ‰¹é‡æ“ä½œ
- **å‹ç¼©**ï¼šå¯ç”¨å‹ç¼©å‡å°‘ç½‘ç»œå’Œå­˜å‚¨å¼€é”€
- **åˆ†åŒºç­–ç•¥**ï¼šåˆç†è®¾è®¡ Key çš„åˆ†åŒºç­–ç•¥
- **ç›‘æ§**ï¼šç›‘æ§ Lagã€ååé‡ã€å»¶è¿Ÿç­‰æŒ‡æ ‡

---

##  å­¦ä¹ èµ„æº

- [Apache Kafka å®˜æ–¹æ–‡æ¡£](https://kafka.apache.org/documentation/)
- [Kafka å¿«é€Ÿå¼€å§‹](https://kafka.apache.org/quickstart)
- [Kafka Streams æ–‡æ¡£](https://kafka.apache.org/documentation/streams/)

---

## ğŸ’¡ å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥

```bash
# Topic æ“ä½œ
bin/kafka-topics.sh --bootstrap-server localhost:9092 --list
bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic my-topic --partitions 3 --replication-factor 2
bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-topic
bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic my-topic

# Consumer Group æ“ä½œ
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-group
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group my-group

# æ§åˆ¶å°å·¥å…·
bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic my-topic
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my-topic --from-beginning

# é…ç½®ç®¡ç†
bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --entity-type topics --entity-name my-topic
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### æŸ¥çœ‹ Consumer Lag

```bash
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --describe \
  --group my-group
```

### æ£€æŸ¥ Topic æ¶ˆæ¯

```bash
# æŸ¥çœ‹æœ€æ–°æ¶ˆæ¯
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
  --topic my-topic \
  --max-messages 10

# æŸ¥çœ‹ç‰¹å®š Partition çš„æ¶ˆæ¯
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
  --topic my-topic \
  --partition 0 \
  --offset 100
```

### ç›‘æ§æŒ‡æ ‡

- **Consumer Lag**ï¼šæ¶ˆè´¹è€…å»¶è¿Ÿ
- **Throughput**ï¼šååé‡
- **Latency**ï¼šå»¶è¿Ÿ
- **Error Rate**ï¼šé”™è¯¯ç‡
