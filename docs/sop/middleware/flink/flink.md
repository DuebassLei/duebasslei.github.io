---
title: Flinkå®ç”¨æ“ä½œç¬”è®°
description: FlinkåŸºç¡€æ ¸å¿ƒçŸ¥è¯†åŠå¸¸ç”¨æ“ä½œæ•´ç†
tag:
  - Flink
  - æµå¤„ç†
  - å¤§æ•°æ®
sidebar: true
outline: [2,3,4]
lastUpdated: true
---

## ğŸ“– ç›®å½•

- [Flink åŸºç¡€æ¦‚å¿µ](#flink-åŸºç¡€æ¦‚å¿µ)
- [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
- [DataStream API](#datastream-api)
- [çŠ¶æ€ç®¡ç†](#çŠ¶æ€ç®¡ç†)
- [æ£€æŸ¥ç‚¹ï¼ˆCheckpointï¼‰](#æ£€æŸ¥ç‚¹checkpoint)
- [çª—å£ï¼ˆWindowï¼‰](#çª—å£window)
- [æ—¶é—´è¯­ä¹‰](#æ—¶é—´è¯­ä¹‰)
- [å¸¸ç”¨æ“ä½œ](#å¸¸ç”¨æ“ä½œ)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## Flink åŸºç¡€æ¦‚å¿µ

### ä»€ä¹ˆæ˜¯ Flinkï¼Ÿ

Apache Flink æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼æµå¤„ç†æ¡†æ¶ï¼Œç”¨äºå¤„ç†æ— ç•Œå’Œæœ‰ç•Œæ•°æ®æµã€‚å®ƒæä¾›äº†ä½å»¶è¿Ÿã€é«˜ååé‡çš„æµå¤„ç†èƒ½åŠ›ã€‚

### æ ¸å¿ƒç‰¹æ€§

- **æµå¤„ç†ä¼˜å…ˆ**ï¼šåŸç”Ÿæ”¯æŒæµå¤„ç†
- **ä½å»¶è¿Ÿ**ï¼šæ¯«ç§’çº§å»¶è¿Ÿ
- **é«˜ååé‡**ï¼šæ”¯æŒå¤§è§„æ¨¡æ•°æ®å¤„ç†
- **çŠ¶æ€ç®¡ç†**ï¼šå¼ºå¤§çš„çŠ¶æ€ç®¡ç†èƒ½åŠ›
- **å®¹é”™æ€§**ï¼šç²¾ç¡®ä¸€æ¬¡è¯­ä¹‰
- **äº‹ä»¶æ—¶é—´**ï¼šæ”¯æŒäº‹ä»¶æ—¶é—´å¤„ç†

### åº”ç”¨åœºæ™¯

- **å®æ—¶æ•°æ®åˆ†æ**ï¼šå®æ—¶æ•°æ®æµåˆ†æ
- **å®æ—¶ç›‘æ§**ï¼šç³»ç»Ÿå®æ—¶ç›‘æ§å’Œå‘Šè­¦
- **å®æ—¶æ¨è**ï¼šå®æ—¶æ¨èç³»ç»Ÿ
- **CEP**ï¼šå¤æ‚äº‹ä»¶å¤„ç†
- **ETL**ï¼šå®æ—¶æ•°æ®è½¬æ¢

### å®‰è£…å’Œå¯åŠ¨

```bash
# ä¸‹è½½ Flink
wget https://archive.apache.org/dist/flink/flink-1.18.0/flink-1.18.0-bin-scala_2.12.tgz
tar -xzf flink-1.18.0-bin-scala_2.12.tgz
cd flink-1.18.0

# å¯åŠ¨é›†ç¾¤
./bin/start-cluster.sh

# åœæ­¢é›†ç¾¤
./bin/stop-cluster.sh

# è®¿é—® Web UI
# http://localhost:8081
```

---

## æ ¸å¿ƒæ¦‚å¿µ

### DataStream

æ— ç•Œæ•°æ®æµï¼ŒFlink çš„åŸºæœ¬æ•°æ®æŠ½è±¡ã€‚

### DataSet

æœ‰ç•Œæ•°æ®é›†ï¼ˆæ‰¹å¤„ç†ï¼‰ï¼ŒFlink 1.12 åæ¨èä½¿ç”¨ DataStream APIã€‚

### Operator

æ•°æ®æµä¸Šçš„æ“ä½œï¼Œå¦‚ mapã€filterã€keyBy ç­‰ã€‚

### Task

æ‰§è¡Œç®—å­çš„åŸºæœ¬å•ä½ã€‚

### Parallelism

å¹¶è¡Œåº¦ï¼Œç®—å­å¹¶è¡Œæ‰§è¡Œçš„ä»»åŠ¡æ•°ã€‚

### Watermark

äº‹ä»¶æ—¶é—´çš„è¿›åº¦æ ‡è®°ï¼Œç”¨äºå¤„ç†ä¹±åºæ•°æ®ã€‚

---

## DataStream API

### åˆ›å»ºæ‰§è¡Œç¯å¢ƒ

```java
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;

// åˆ›å»ºæµæ‰§è¡Œç¯å¢ƒ
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

// è®¾ç½®å¹¶è¡Œåº¦
env.setParallelism(4);
```

### æ•°æ®æº

```java
// ä»é›†åˆåˆ›å»º
DataStream<String> stream = env.fromCollection(Arrays.asList("a", "b", "c"));

// ä»æ–‡ä»¶åˆ›å»º
DataStream<String> stream = env.readTextFile("file:///path/to/file");

// ä» Socket åˆ›å»º
DataStream<String> stream = env.socketTextStream("localhost", 9999);

// ä» Kafka åˆ›å»º
Properties props = new Properties();
props.setProperty("bootstrap.servers", "localhost:9092");
props.setProperty("group.id", "flink-consumer");

FlinkKafkaConsumer<String> consumer = new FlinkKafkaConsumer<>(
    "topic",
    new SimpleStringSchema(),
    props
);
DataStream<String> stream = env.addSource(consumer);
```

### è½¬æ¢æ“ä½œ

```java
// Map
DataStream<Integer> mapped = stream.map(s -> s.length());

// Filter
DataStream<String> filtered = stream.filter(s -> s.startsWith("a"));

// FlatMap
DataStream<String> flatMapped = stream.flatMap((String value, Collector<String> out) -> {
    for (String word : value.split(" ")) {
        out.collect(word);
    }
});

// KeyBy
KeyedStream<String, String> keyed = stream.keyBy(s -> s.substring(0, 1));

// Reduce
DataStream<Integer> reduced = keyed.reduce((a, b) -> a + b);
```

### æ•°æ®è¾“å‡º

```java
// è¾“å‡ºåˆ°æ§åˆ¶å°
stream.print();

// è¾“å‡ºåˆ°æ–‡ä»¶
stream.writeAsText("file:///path/to/output");

// è¾“å‡ºåˆ° Kafka
FlinkKafkaProducer<String> producer = new FlinkKafkaProducer<>(
    "topic",
    new SimpleStringSchema(),
    props
);
stream.addSink(producer);
```

---

## çŠ¶æ€ç®¡ç†

### çŠ¶æ€ç±»å‹

#### 1. ValueState

```java
public class CountFunction extends RichFlatMapFunction<String, Tuple2<String, Integer>> {
    private transient ValueState<Integer> count;
    
    @Override
    public void open(Configuration config) {
        ValueStateDescriptor<Integer> descriptor =
            new ValueStateDescriptor<>("count", Integer.class);
        count = getRuntimeContext().getState(descriptor);
    }
    
    @Override
    public void flatMap(String value, Collector<Tuple2<String, Integer>> out) throws Exception {
        Integer currentCount = count.value();
        if (currentCount == null) {
            currentCount = 0;
        }
        currentCount++;
        count.update(currentCount);
        out.collect(new Tuple2<>(value, currentCount));
    }
}
```

#### 2. ListState

```java
ListStateDescriptor<String> descriptor = new ListStateDescriptor<>("list", String.class);
ListState<String> listState = getRuntimeContext().getListState(descriptor);
```

#### 3. MapState

```java
MapStateDescriptor<String, Integer> descriptor = 
    new MapStateDescriptor<>("map", String.class, Integer.class);
MapState<String, Integer> mapState = getRuntimeContext().getMapState(descriptor);
```

### çŠ¶æ€åç«¯

```java
// HashMapStateBackendï¼ˆå†…å­˜ï¼‰
env.setStateBackend(new HashMapStateBackend());

// EmbeddedRocksDBStateBackendï¼ˆRocksDBï¼‰
EmbeddedRocksDBStateBackend rocksDBStateBackend = new EmbeddedRocksDBStateBackend(true);
rocksDBStateBackend.setDbStoragePath("/flink/rocksdb-storage");
env.setStateBackend(rocksDBStateBackend);
```

---

## æ£€æŸ¥ç‚¹ï¼ˆCheckpointï¼‰

### å¯ç”¨æ£€æŸ¥ç‚¹

```java
// å¯ç”¨æ£€æŸ¥ç‚¹
env.enableCheckpointing(60000); // 60ç§’

// é…ç½®æ£€æŸ¥ç‚¹
CheckpointConfig checkpointConfig = env.getCheckpointConfig();
checkpointConfig.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);
checkpointConfig.setMinPauseBetweenCheckpoints(500);
checkpointConfig.setCheckpointTimeout(600000);
checkpointConfig.setMaxConcurrentCheckpoints(1);
checkpointConfig.enableExternalizedCheckpoints(
    CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION
);

// è®¾ç½®æ£€æŸ¥ç‚¹å­˜å‚¨
checkpointConfig.setCheckpointStorage("hdfs://namenode:9000/flink/checkpoints");
```

### ä¿å­˜ç‚¹ï¼ˆSavepointï¼‰

```bash
# åˆ›å»ºä¿å­˜ç‚¹
flink savepoint <jobId> <savepointPath>

# ä»ä¿å­˜ç‚¹æ¢å¤
flink run -s <savepointPath> <jarFile>

# å–æ¶ˆä½œä¸šå¹¶åˆ›å»ºä¿å­˜ç‚¹
flink cancel -s <savepointPath> <jobId>
```

---

## çª—å£ï¼ˆWindowï¼‰

### æ—¶é—´çª—å£

```java
// æ»šåŠ¨æ—¶é—´çª—å£
stream.keyBy(...)
    .window(TumblingEventTimeWindows.of(Time.seconds(5)))
    .sum("value");

// æ»‘åŠ¨æ—¶é—´çª—å£
stream.keyBy(...)
    .window(SlidingEventTimeWindows.of(Time.seconds(10), Time.seconds(5)))
    .sum("value");

// ä¼šè¯çª—å£
stream.keyBy(...)
    .window(EventTimeSessionWindows.withGap(Time.minutes(5)))
    .sum("value");
```

### è®¡æ•°çª—å£

```java
// æ»šåŠ¨è®¡æ•°çª—å£
stream.keyBy(...)
    .countWindow(100)
    .sum("value");

// æ»‘åŠ¨è®¡æ•°çª—å£
stream.keyBy(...)
    .countWindow(100, 10)
    .sum("value");
```

### çª—å£å‡½æ•°

```java
// å¢é‡èšåˆ
stream.keyBy(...)
    .window(...)
    .aggregate(new AggregateFunction<Event, Long, Long>() {
        @Override
        public Long createAccumulator() {
            return 0L;
        }
        
        @Override
        public Long add(Event value, Long accumulator) {
            return accumulator + 1;
        }
        
        @Override
        public Long getResult(Long accumulator) {
            return accumulator;
        }
        
        @Override
        public Long merge(Long a, Long b) {
            return a + b;
        }
    });

// å…¨çª—å£å‡½æ•°
stream.keyBy(...)
    .window(...)
    .apply(new WindowFunction<Event, String, String, TimeWindow>() {
        @Override
        public void apply(String key, TimeWindow window, 
                         Iterable<Event> values, Collector<String> out) {
            // å¤„ç†çª—å£ä¸­çš„æ‰€æœ‰å…ƒç´ 
        }
    });
```

---

## æ—¶é—´è¯­ä¹‰

### å¤„ç†æ—¶é—´ï¼ˆProcessing Timeï¼‰

```java
env.setStreamTimeCharacteristic(TimeCharacteristic.ProcessingTime);
```

### äº‹ä»¶æ—¶é—´ï¼ˆEvent Timeï¼‰

```java
env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);

// åˆ†é…æ—¶é—´æˆ³å’Œç”Ÿæˆ Watermark
stream.assignTimestampsAndWatermarks(
    WatermarkStrategy.<Event>forBoundedOutOfOrderness(Duration.ofSeconds(20))
        .withTimestampAssigner((event, timestamp) -> event.getTimestamp())
);
```

### æ°´å°ï¼ˆWatermarkï¼‰

```java
// æœ‰åºæ•°æ®
stream.assignTimestampsAndWatermarks(
    WatermarkStrategy.<Event>forMonotonousTimestamps()
        .withTimestampAssigner((event, timestamp) -> event.getTimestamp())
);

// ä¹±åºæ•°æ®
stream.assignTimestampsAndWatermarks(
    WatermarkStrategy.<Event>forBoundedOutOfOrderness(Duration.ofSeconds(20))
        .withTimestampAssigner((event, timestamp) -> event.getTimestamp())
);
```

---

## å¸¸ç”¨æ“ä½œ

### è¿æ¥ï¼ˆJoinï¼‰

```java
// çª—å£è¿æ¥
stream1.join(stream2)
    .where(e1 -> e1.getKey())
    .equalTo(e2 -> e2.getKey())
    .window(TumblingEventTimeWindows.of(Time.seconds(5)))
    .apply(new JoinFunction<Event1, Event2, String>() {
        @Override
        public String join(Event1 first, Event2 second) {
            return first.getValue() + "-" + second.getValue();
        }
    });
```

### ä¾§è¾“å‡ºï¼ˆSide Outputï¼‰

```java
// å®šä¹‰ä¾§è¾“å‡ºæ ‡ç­¾
OutputTag<String> outputTag = new OutputTag<String>("side-output"){};

// ä½¿ç”¨ä¾§è¾“å‡º
SingleOutputStreamOperator<String> mainStream = stream
    .process(new ProcessFunction<String, String>() {
        @Override
        public void processElement(String value, Context ctx, Collector<String> out) {
            if (value.startsWith("ERROR")) {
                ctx.output(outputTag, value);
            } else {
                out.collect(value);
            }
        }
    });

// è·å–ä¾§è¾“å‡ºæµ
DataStream<String> sideStream = mainStream.getSideOutput(outputTag);
```

---

## æœ€ä½³å®è·µ

### æ€§èƒ½ä¼˜åŒ–

- **åˆç†è®¾ç½®å¹¶è¡Œåº¦**ï¼šæ ¹æ®æ•°æ®é‡å’Œèµ„æºè®¾ç½®
- **ä½¿ç”¨ KeyBy**ï¼šåˆç†ä½¿ç”¨ KeyBy è¿›è¡Œæ•°æ®åˆ†åŒº
- **çŠ¶æ€ä¼˜åŒ–**ï¼šåˆç†é€‰æ‹©çŠ¶æ€åç«¯
- **æ£€æŸ¥ç‚¹ä¼˜åŒ–**ï¼šåˆç†è®¾ç½®æ£€æŸ¥ç‚¹é—´éš”

### å®¹é”™è®¾è®¡

- **å¯ç”¨æ£€æŸ¥ç‚¹**ï¼šç”Ÿäº§ç¯å¢ƒå¿…é¡»å¯ç”¨
- **çŠ¶æ€åç«¯**ï¼šä½¿ç”¨æŒä¹…åŒ–çŠ¶æ€åç«¯
- **ä¿å­˜ç‚¹**ï¼šå®šæœŸåˆ›å»ºä¿å­˜ç‚¹

### æ—¶é—´å¤„ç†

- **ä½¿ç”¨äº‹ä»¶æ—¶é—´**ï¼šå‡†ç¡®çš„æ—¶é—´è¯­ä¹‰
- **åˆç†è®¾ç½® Watermark**ï¼šæ ¹æ®æ•°æ®å»¶è¿Ÿè®¾ç½®
- **å¤„ç†å»¶è¿Ÿæ•°æ®**ï¼šä½¿ç”¨ä¾§è¾“å‡ºå¤„ç†å»¶è¿Ÿæ•°æ®

---

##  å­¦ä¹ èµ„æº

- [Flink å®˜æ–¹æ–‡æ¡£](https://flink.apache.org/docs/)
- [Flink ä¸­æ–‡æ–‡æ¡£](https://flink.apache.org/zh/docs/)
- [Flink ç¤ºä¾‹](https://github.com/apache/flink/tree/master/flink-examples)

---

## ğŸ’¡ å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥

```bash
# æäº¤ä½œä¸š
flink run -c com.example.MainClass app.jar

# åˆ—å‡ºè¿è¡Œä¸­çš„ä½œä¸š
flink list

# å–æ¶ˆä½œä¸š
flink cancel <jobId>

# æŸ¥çœ‹ä½œä¸šè¯¦æƒ…
flink info <jobId>

# åˆ›å»ºä¿å­˜ç‚¹
flink savepoint <jobId> <savepointPath>

# ä»ä¿å­˜ç‚¹æ¢å¤
flink run -s <savepointPath> app.jar
```

